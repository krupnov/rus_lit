{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5269844224957405958\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11585093078672622903\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11572476197311652601\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4827840512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11421831612208046323\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "cyr_chars = ['а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й',\n",
    "             'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'х',\n",
    "             'ф', 'ц', 'ч', 'щ', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n",
    "\n",
    "char2num = {}\n",
    "num2char = {}\n",
    "\n",
    "for i, ch in enumerate(cyr_chars):\n",
    "    char2num[ch] = i + 1\n",
    "    num2char[i + 1] = ch\n",
    "\n",
    "char2num[' '] = 35\n",
    "num2char[35] = ' '\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = '/home/ilya/Documents/git/rus_lit/data_converters/converted'\n",
    "\n",
    "with open(data_file_name, 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data = [s.strip() for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5654\n",
      "[['том', 'третий', 'государственное', 'издательство', 'художественной', 'литературы'], ['содержание', 'руслан', 'и', 'людмила', 'кавказский', 'пленник', 'гавриилиада', 'братьяразбойники', 'бахчисарайский', 'фонтан', 'цыганы', 'граф', 'нулин', 'полтава', 'тазит', 'домик', 'в', 'коломне', 'анджело', 'медный', 'всадник', 'завершнное', 'планы', 'отрывки', 'наброски', 'монах', 'бова', 'исповедь', 'поэма', 'о', 'гетеристах', 'иордаки', 'актеон', 'вадим', 'бова', 'мстислав', 'агасфер', 'кирджали', 'казачка', 'и', 'черкес', 'езерский', 'юдифь', 'из', 'ранних', 'редакции', 'с'], ['поэмы', 'пушкина', 'примечания', 'руслан', 'и', 'людмила', 'посвящение', 'для', 'вас', 'души', 'моей', 'царицы', 'красавицы', 'для', 'вас', 'одних', 'времен', 'минувших', 'небылицы', 'в', 'часы', 'досугов', 'золотых', 'под', 'шепот', 'старины', 'болтливой', 'рукою', 'верной', 'я', 'писал'], ['примите', 'ж', 'вы', 'мой', 'труд', 'игривый'], ['ничьих', 'не', 'требуя', 'похвал', 'счастлив', 'уж', 'я', 'надеждой', 'сладкой', 'что', 'дева', 'с', 'трепетом', 'любви', 'посмотрит', 'может', 'быть', 'украдкой', 'на', 'песни', 'грешные', 'мои'], ['златая', 'цепь', 'на', 'дубе', 'том', 'и', 'днем', 'и', 'ночью', 'кот', 'ученый', 'все', 'ходит', 'по', 'цепи', 'кругом'], ['идет', 'направо', 'песнь', 'заводит', 'налево', 'сказку', 'говорит'], ['там', 'чудеса', 'там', 'леший', 'бродит', 'русалка', 'на', 'ветвях', 'сидит'], ['там', 'на', 'неведомых', 'дорожках', 'следы', 'невиданных', 'зверей'], ['избушка', 'там', 'на', 'курьих', 'ножках', 'стоит', 'без', 'окон', 'без', 'дверей'], ['там', 'лес', 'и', 'дол', 'видений', 'полны'], ['там', 'о', 'заре', 'прихлынут', 'волны', 'на', 'брег', 'песчаный', 'и', 'пустой', 'и', 'тридцать', 'витязей', 'прекрасных', 'чредой', 'из', 'вод', 'выходят', 'ясных', 'и', 'с', 'ними', 'дядька', 'их', 'морской'], ['там', 'королевич', 'мимоходом', 'пленяет', 'грозного', 'царя'], ['там', 'в', 'облаках', 'перед', 'народом', 'через', 'леса', 'через', 'моря', 'колдун', 'несет', 'богатыря'], ['в', 'темнице', 'там', 'царевна', 'тужит', 'а', 'бурый', 'волк', 'ей', 'верно', 'служит'], ['там', 'ступа', 'с', 'бабою', 'ягой', 'идет', 'бредет', 'сама', 'собой'], ['там', 'царь', 'кащей', 'над', 'златом', 'чахнет'], ['и', 'там', 'я', 'был', 'и', 'мед', 'я', 'пил'], ['под', 'ним', 'сидел', 'и', 'кот', 'ученый', 'свои', 'мне', 'сказки', 'говорил'], ['одну', 'я', 'помню', 'сказку', 'эту', 'поведаю', 'теперь', 'я', 'свету']]\n"
     ]
    }
   ],
   "source": [
    "MIN_WORDS_COUNT = 6\n",
    "word_sent = [s.split(' ') for s in data]\n",
    "filtered_sent = [w for w in word_sent if len(w) >= MIN_WORDS_COUNT]\n",
    "print(len(filtered_sent))\n",
    "print(filtered_sent[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 50\n",
    "\n",
    "learning = list()\n",
    "for word_sent in filtered_sent:\n",
    "    sent = ''\n",
    "    for w in word_sent:\n",
    "        if len(sent + w) > MAX_SENTENCE_LENGTH:\n",
    "            break\n",
    "        sent = sent + w + ' '\n",
    "    learning.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2num(learning):\n",
    "    nums_col = []\n",
    "    for s in learning:\n",
    "        nums_col.append([-1] + [char2num[w] for w in s])\n",
    "    return nums_col\n",
    "\n",
    "data_nums = convert2num(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "ready_data = []\n",
    "labels = []\n",
    "\n",
    "for dd in data_nums:\n",
    "    for i, _ in enumerate(dd):\n",
    "        ready_data.append(pad_sequences([dd[:i + 1]], maxlen=MAX_SENTENCE_LENGTH + 1, padding='post')[0])\n",
    "        labels.append(dd[i + 1] if i < len(dd) - 1 else -2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras.utils as ku\n",
    "\n",
    "ready_data = numpy.asarray(ready_data)\n",
    "labels = numpy.asarray(labels)\n",
    "labels = ku.to_categorical(labels, num_classes=len(char2num) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257336, 51)\n",
      "(257336, 36)\n"
     ]
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_model(predictors, label, total_words):\n",
    "    input_len = MAX_SENTENCE_LENGTH + 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(predictors, label, epochs=30, verbose=1, validation_split=.1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ilya/anaconda3/envs/text_converter/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ilya/anaconda3/envs/text_converter/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ilya/anaconda3/envs/text_converter/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 231602 samples, validate on 25734 samples\n",
      "Epoch 1/30\n",
      "231602/231602 [==============================] - 297s 1ms/step - loss: 2.9954 - val_loss: 2.6622\n",
      "Epoch 2/30\n",
      "231602/231602 [==============================] - 299s 1ms/step - loss: 2.5806 - val_loss: 2.4940\n",
      "Epoch 3/30\n",
      "231602/231602 [==============================] - 295s 1ms/step - loss: 2.4330 - val_loss: 2.3081\n",
      "Epoch 4/30\n",
      "231602/231602 [==============================] - 310s 1ms/step - loss: 2.2840 - val_loss: 2.2006\n",
      "Epoch 5/30\n",
      "231602/231602 [==============================] - 312s 1ms/step - loss: 2.1625 - val_loss: 2.0822\n",
      "Epoch 6/30\n",
      "231602/231602 [==============================] - 315s 1ms/step - loss: 2.0527 - val_loss: 2.0211\n",
      "Epoch 7/30\n",
      "231602/231602 [==============================] - 303s 1ms/step - loss: 1.9607 - val_loss: 1.9387\n",
      "Epoch 8/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.8895 - val_loss: 1.8984\n",
      "Epoch 9/30\n",
      "231602/231602 [==============================] - 297s 1ms/step - loss: 1.8303 - val_loss: 1.8628\n",
      "Epoch 10/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.7817 - val_loss: 1.8390\n",
      "Epoch 11/30\n",
      "231602/231602 [==============================] - 294s 1ms/step - loss: 1.7380 - val_loss: 1.8496\n",
      "Epoch 12/30\n",
      "231602/231602 [==============================] - 297s 1ms/step - loss: 1.7021 - val_loss: 1.8202\n",
      "Epoch 13/30\n",
      "231602/231602 [==============================] - 306s 1ms/step - loss: 1.6669 - val_loss: 1.8128\n",
      "Epoch 14/30\n",
      "231602/231602 [==============================] - 294s 1ms/step - loss: 1.6400 - val_loss: 1.8083\n",
      "Epoch 15/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.6108 - val_loss: 1.7910\n",
      "Epoch 16/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.5888 - val_loss: 1.7944\n",
      "Epoch 17/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.5631 - val_loss: 1.7809\n",
      "Epoch 18/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.5460 - val_loss: 1.7916\n",
      "Epoch 19/30\n",
      "231602/231602 [==============================] - 296s 1ms/step - loss: 1.5301 - val_loss: 1.7982\n",
      "Epoch 20/30\n",
      "231602/231602 [==============================] - 298s 1ms/step - loss: 1.5094 - val_loss: 1.7963\n",
      "Epoch 21/30\n",
      "231602/231602 [==============================] - 298s 1ms/step - loss: 1.4940 - val_loss: 1.7983\n",
      "Epoch 22/30\n",
      "231602/231602 [==============================] - 298s 1ms/step - loss: 1.4810 - val_loss: 1.7777\n",
      "Epoch 23/30\n",
      "231602/231602 [==============================] - 298s 1ms/step - loss: 1.4672 - val_loss: 1.8062\n",
      "Epoch 24/30\n",
      "231602/231602 [==============================] - 298s 1ms/step - loss: 1.4588 - val_loss: 1.8106\n",
      "Epoch 25/30\n",
      "231602/231602 [==============================] - 299s 1ms/step - loss: 1.4409 - val_loss: 1.8104\n",
      "Epoch 26/30\n",
      "231602/231602 [==============================] - 301s 1ms/step - loss: 1.4325 - val_loss: 1.8064\n",
      "Epoch 27/30\n",
      "231602/231602 [==============================] - 302s 1ms/step - loss: 1.4229 - val_loss: 1.8284\n",
      "Epoch 28/30\n",
      "231602/231602 [==============================] - 302s 1ms/step - loss: 1.4098 - val_loss: 1.8108\n",
      "Epoch 29/30\n",
      "231602/231602 [==============================] - 302s 1ms/step - loss: 1.3985 - val_loss: 1.8114\n",
      "Epoch 30/30\n",
      "231602/231602 [==============================] - 304s 1ms/step - loss: 1.3919 - val_loss: 1.8134\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = create_model(ready_data, labels, len(char2num) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, char_num, model):\n",
    "    nex = len(seed_text) + 1\n",
    "    tokinized = pad_sequences([[-1] + [char2num[ch] for ch in seed_text]], maxlen=MAX_SENTENCE_LENGTH + 1, padding='post')\n",
    "    for i in range(char_num):\n",
    "        next_char = model.predict_classes(tokinized)\n",
    "        tokinized[0][nex] = next_char[0]\n",
    "        nex = nex + 1\n",
    "    print(''.join(num2char[ch] for ch in tokinized[0] if ch in num2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "петушок объявил ее при ней просил \n"
     ]
    }
   ],
   "source": [
    "generate_text('пету', 30, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/ilya/Documents/git/rus_lit/models/baseline/saved22.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text converter",
   "language": "python",
   "name": "tex_con"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
